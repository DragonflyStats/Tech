Big Data Tools

(1 point possible)
Why is using traditional analysis tools for big data a poor choice?

* Storage is becoming less expensive.  
* The time to read from a 1 TB drive is 3 hours.  
* Big data does not fit on a single machine.  
* CPUs are getting faster and faster every year.

------------------------------------------------------------------------------------------

Using Cluster Computing for Big Data

(1 point possible)
Which of the following properties does modern cluster computing have:

 Uses premium hardware  Uses consumer grade hardware  Uses complex hardware  Uses complex software  Easy to add capacity
- This answer is unanswered.
Note: Make sure you select all of the correct options—there may be more than one!

------------------------------------------------------------------------------------------

Using Divide and Conquer

(1 point possible)
What are some of the challenges of using divide and conquer:

 Moving data is very expensive  Using a single machine is faster than multiple machines  Having many machines means having to deal with many failures  Having many machines means having to deal with slow machines  Using hash tables for very large documents works well
- This answer is unanswered.
Note: Make sure you select all of the correct options—there may be more than one!


------------------------------------------------------------------------------------------

Map Reduce deals with failures and slow tasks by re-launching the tasks on other machines. This functionality is enabled by the requirement that individual tasks in a Map Reduce job are idempotent and have no side effects. These two properties mean that given the same input, re-executing a task will always produce the same result and will not change other state. So, the results and end condition of the system are the same, whether a task is executed once or a thousand times.

------------------------------------------------------------------------------------------

MapReduce

(1 point possible)
Which of the following problems does a MapReduce implementation handle?

 Recovering from machine failures  Shuffling data between the Map and Reduce functions  Running the Map and Reduce functions on many machines  Automatically parallelizing an algorithm  Recovering from slow machines
- This answer is unanswered.
Note: Make sure you select all of the correct options—there may be more than one!

-----------------------------------------------------------------------------------------

Hadoop/Map Reduce and Apache Spark Differences

(1 point possible)
Apache Spark is often faster than a traditional Hadoop/MapReduce implementation because:

 It sends less data over the network  Results do not need to be written to disk  It detects machine failures more quickly  It replicates the output of each task to recover from failures quickly  Results do not need to be serialized
- This answer is unanswered.
Note: Make sure you select all of the correct options—there may be more than one!

------------------------------------------------------------------------------------------

Database Advantages

(1 point possible)
Which of the following are NOT advantages of databases:

 They have a well-defined structure  They use indicies for high performance  They have a rigid structure  They guarantee data consistency  They have poor support for sparse data
